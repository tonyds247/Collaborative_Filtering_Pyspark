{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca26b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bcbcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0583130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8602714f",
   "metadata": {},
   "source": [
    "### About Data\n",
    "- user_id - ID of the reviewer\n",
    "- product_id of the product\n",
    "- user - name of the reviewer\n",
    "- rating - rating of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced79fa",
   "metadata": {},
   "source": [
    "### Load Data and Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5f56a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:14:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/30 20:14:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/30 20:14:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a208fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"Products_ThoiTrangNam_rating_raw.csv\",header=True\n",
    "                      ,inferSchema=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f7f049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024482"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82594e4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+------------------+------+\n",
      "|product_id|user_id|              user|rating|\n",
      "+----------+-------+------------------+------+\n",
      "|       190|      1|      karmakyun2nd|     5|\n",
      "|       190|      2|  tranquangvinh_vv|     5|\n",
      "|       190|      3|nguyenquoctoan2005|     5|\n",
      "|       190|      4|    nguyenthuyhavi|     5|\n",
      "|       190|      5|      luonganh5595|     5|\n",
      "+----------+-------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c61edaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3230c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data.select(['product_id', 'rating', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4933ccf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f67c41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "product_id  0\n",
       "rating      0\n",
       "user_id     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check isnull\n",
    "data_sub.select([count(when(col(c).isNull(), c)).alias(c) for c in data_sub.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf553a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### distinct users and and Movies\n",
    "users = data_sub.select(\"user_id\").distinct().count() \n",
    "products = data_sub.select(\"product_id\").distinct().count() \n",
    "numerator = data_sub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a8fb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "650636"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(numerator, users, products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf170d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20343435812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of ratings matrix could contain if no empty cells\n",
    "denominator = users * products \n",
    "### ratio 1M rating/20B --- sparse matrix\n",
    "denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f451fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.9999496406600406)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating sparsity\n",
    "## hard to expect good rmse\n",
    "sparsity = 1 - (numerator*1.0 / denominator) \n",
    "print (\"Sparsity: \"), sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d3f556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_sub.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20b32f",
   "metadata": {},
   "source": [
    "### StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff09809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 32:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='product_id', outputCol='product_id_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(data_sub)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "data_indexed = indexer_model.transform(data_sub)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "indexer1 = StringIndexer(inputCol='user_id',\n",
    "                         outputCol='user_id_idx')\n",
    "indexer1_model = indexer1.fit(data_indexed) \n",
    "data_indexed = indexer1_model.transform(data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b2262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:11 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "+----------+------+-------+--------------+-----------+\n",
      "|product_id|rating|user_id|product_id_idx|user_id_idx|\n",
      "+----------+------+-------+--------------+-----------+\n",
      "|       190|     5|      1|         367.0|   113654.0|\n",
      "|       190|     5|      2|         367.0|    50699.0|\n",
      "|       190|     5|      3|         367.0|   284299.0|\n",
      "|       190|     5|      4|         367.0|   376354.0|\n",
      "|       190|     5|      5|         367.0|     6462.0|\n",
      "+----------+------+-------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_indexed.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d83b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id_idx</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_idx</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "product_id      0\n",
       "rating          0\n",
       "user_id         0\n",
       "product_id_idx  0\n",
       "user_id_idx     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check isnull again\n",
    "data_indexed.select([count(when(col(c).isNull(), c)).alias(c) for c in data_indexed.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa29651",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9e2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0.8 / 0.2\n",
    "(training, test) = data_indexed.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd2880e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:14 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:16 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:========>                                                 (1 + 6) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:18 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 39:>                                                         (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:19 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 0) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:23 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:25 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                        (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:27 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/30 20:15:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/03/30 20:15:29 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:31 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 49:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:35 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:============================>                            (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:38 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                        (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:41 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 52:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:44 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                        (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:47 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:50 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:>                                                        (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:54 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:55 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                        (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:15:59 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter=5,\n",
    "          regParam=0.01,\n",
    "          rank = 25,\n",
    "          userCol=\"user_id_idx\",\n",
    "          itemCol=\"product_id_idx\",\n",
    "          ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", nonnegative=True)\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690ecb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "567e141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:>                                                         (0 + 0) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:02 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:>                 (0 + 0) / 7][Stage 85:>                (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:03 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 71:>   (0 + 0) / 7][Stage 85:>  (0 + 0) / 10][Stage 86:>  (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:05 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:==================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:08 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+------+----------+\n",
      "|product_id_idx|user_id_idx|rating|prediction|\n",
      "+--------------+-----------+------+----------+\n",
      "|        8638.0|       31.0|     5|  7.683725|\n",
      "|         148.0|       31.0|     1|  2.396131|\n",
      "|        2122.0|       34.0|     5| 4.6566224|\n",
      "|        2122.0|      133.0|     5| 4.5032015|\n",
      "|        1088.0|      148.0|     5| 4.7659764|\n",
      "+--------------+-----------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 102:===================================================>   (16 + 1) / 17]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select([\"product_id_idx\", \"user_id_idx\",\n",
    "                    \"rating\", \"prediction\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c233b32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:13 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 122:>                (0 + 0) / 7][Stage 136:>               (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:14 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 122:>  (0 + 0) / 7][Stage 136:> (0 + 0) / 10][Stage 137:> (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:16 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 137:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:20 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:24 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 172:======================================>                  (6 + 3) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:16:26 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 173:>                                                        (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.6412937567645896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\") \n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292feaaf",
   "metadata": {},
   "source": [
    "### Result\n",
    "- bad Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d01bdd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "# initialize the ALS model\n",
    "#als_model = ALS(userCol='user_id_idx', itemCol='product_id_idx', ratingCol='rating', coldStartStrategy='drop')\n",
    "# create the parameter grid\n",
    "#params = ParamGridBuilder().addGrid(als_model.regParam, [.01, .05, .1, .15]).addGrid(als_model.rank, [10, 50, 100, 150]).build()\n",
    "#instantiating crossvalidator estimator\n",
    "#cv = CrossValidator(estimator=als_model, estimatorParamMaps=params, evaluator=evaluator, parallelism=4)\n",
    "#best_model = cv.fit(data_indexed)\n",
    "#model = best_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c6741",
   "metadata": {},
   "source": [
    "### Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cba16070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:17 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:19 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:========================>                                (3 + 4) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:21 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 176:>                                                        (0 + 7) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:23 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:24 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 179:================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:26 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:27 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 183:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:29 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 185:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:31 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 186:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:34 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 187:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:37 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 188:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:39 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 189:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:41 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 190:======================>                                 (4 + 6) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:44 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 191:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:46 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 192:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:48 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 193:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:50 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:53 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 195:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:56 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 196:===========>                                            (2 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:17:58 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 197:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:00 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 198:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:03 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 199:============================>                           (5 + 5) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:04 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 200:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:07 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 202:>                                                       (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:09 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 202:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:12 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 203:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:13 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:16 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:18 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:>                (0 + 0) / 7][Stage 252:>               (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:19 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 228:>  (0 + 0) / 7][Stage 252:> (0 + 0) / 10][Stage 253:> (0 + 0) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:21 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 253:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:23 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:28 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:========================>                               (7 + 9) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:18:30 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 309:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rootmse =1.0815501961792808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als_t = ALS(maxIter=10,\n",
    "         regParam=0.2,\n",
    "            rank = 50,\n",
    "         userCol=\"user_id_idx\",\n",
    "          itemCol=\"product_id_idx\",\n",
    "          ratingCol=\"rating\",\n",
    "         coldStartStrategy='drop',\n",
    "         nonnegative=True)\n",
    "model_t = als_t.fit(training)\n",
    "predictions_t = model_t.transform(test)\n",
    "rmse_t = evaluator.evaluate(predictions_t)\n",
    "\n",
    "print('rootmse =' +str(rmse_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a8f65",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "- the result is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd701e1",
   "metadata": {},
   "source": [
    "### Recommend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27dc4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_recs = model_t.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "435f12b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:19:00 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 358:>                                                        (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/30 20:22:39 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 358:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user_id_idx=31, recommendations=[Row(product_id_idx=24311, rating=5.205354690551758), Row(product_id_idx=24530, rating=5.156948566436768), Row(product_id_idx=21747, rating=5.105452060699463), Row(product_id_idx=23243, rating=5.101497173309326), Row(product_id_idx=29670, rating=5.064798831939697), Row(product_id_idx=17271, rating=5.025424957275391), Row(product_id_idx=18881, rating=5.009730339050293), Row(product_id_idx=21690, rating=5.002012252807617), Row(product_id_idx=27479, rating=4.996496200561523), Row(product_id_idx=20285, rating=4.994470119476318)])\n",
      "\n",
      "\n",
      "Row(user_id_idx=34, recommendations=[Row(product_id_idx=24311, rating=5.2627363204956055), Row(product_id_idx=29670, rating=5.251367092132568), Row(product_id_idx=24530, rating=5.145304203033447), Row(product_id_idx=21747, rating=5.055899143218994), Row(product_id_idx=25302, rating=5.027964115142822), Row(product_id_idx=22947, rating=5.023828506469727), Row(product_id_idx=27115, rating=5.017805099487305), Row(product_id_idx=16396, rating=5.012878894805908), Row(product_id_idx=19394, rating=4.973663806915283), Row(product_id_idx=29538, rating=4.9713616371154785)])\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for user in ser_recs.head(2):\n",
    "    print(user)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
